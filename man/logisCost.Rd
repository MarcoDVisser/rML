% Generated by roxygen2 (4.0.1): do not edit by hand
\name{logisCost}
\alias{logisCost}
\alias{logisGrad}
\title{Cost function for a logistic classifier}
\usage{
logisCost(theta, X, y, lambda)

logisGrad(theta, X, y, lambda)
}
\arguments{
\item{theta}{numeric vector of parameters}

\item{X}{design matrix: an array of numeric variables or features
including intercepts}

\item{y}{binary classification vector}

\item{lambda}{regularization coefficient}
}
\description{
calculates the cost and derivatives for a simple
logistic classifier

Gradient function for a logistic classifier
}
\examples{
X<-array(rnorm(200),dim=c(100,2))
y<-sqrt(X[,2]^2+X[,1]^2)<.5
designX<-mapFeat(X)
designX<-cbind(rep(1,100),designX)
theta<-rep(0,ncol(designX))
lambda<-1
logisCost(theta,designX,y,lambda)
logisGrad(theta,designX,y,lambda)
optim(theta,logisCost,logisGrad,X=designX,y=y,lambda=1,method="BFGS")
}
\author{
Marco D. Visser
}

